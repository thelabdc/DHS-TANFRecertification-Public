{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data csv created at the end of 01-outcomes-prep.R:\n",
    "df_tanf = pd.read_csv('df_replication_anon.csv', na_values=['NA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to remove times from some date-times, and account for 2 date formats:\n",
    "from datetime import datetime\n",
    "strptime = datetime.strptime\n",
    "\n",
    "def dater(x):\n",
    "    if '/' in x:\n",
    "        return strptime(x, '%m/%d/%Y')\n",
    "    else:\n",
    "        return strptime(x, '%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recode appt_date to include only dates in a single format: \n",
    "df_tanf['appt_date'] = df_tanf.appt_date.apply(lambda x: x.split(' ')[0]).apply(dater)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Tools for anonymizing pandas DataFrames.\n",
    "\n",
    "@author Kevin H. Wilson <kevin.wilson@dc.gov>\n",
    "\"\"\"\n",
    "import math\n",
    "\n",
    "try:\n",
    "  import secrets\n",
    "except ImportError:\n",
    "  from . import secretsport as secrets\n",
    "\n",
    "\n",
    "def anonymize_str_columns(df, cols, current_map=None, inplace=False):\n",
    "  \"\"\"\n",
    "  Given a collection of columns `cols` in a DataFrame `df`,\n",
    "  assume they all are strings. Replace all the values, including\n",
    "  those common across columns, with a unique, random string.\n",
    "  If `current_map` is not None, then it will be used first to determine\n",
    "  the values of the columns.\n",
    "\n",
    "  For example, if `df` looks like::\n",
    "\n",
    "    A | B | C\n",
    "   -----------\n",
    "    a | b | x\n",
    "    a | a | y\n",
    "    b | c | z\n",
    "\n",
    "  and `cols == ['A', 'B']`, then the output might look like::\n",
    "\n",
    "    A | B | C\n",
    "   -----------\n",
    "    1 | 2 | x\n",
    "    1 | 1 | y\n",
    "    2 | 3 | z\n",
    "    \n",
    "  This function also preserves missing data as misisng.\n",
    "\n",
    "  Args:\n",
    "    df (pd.DataFrame): The DataFrame whose columns to anonymize\n",
    "    cols (list[str]): The list of column names to anonymize\n",
    "    current_map (dict[str, str]|None): The map of keys to values to append to\n",
    "    inplace (bool): Should the anonymization be done in place?\n",
    "\n",
    "  Returns:\n",
    "    pd.DataFrame: The anonymized DataFrame\n",
    "    dict[str, str]: The map of anonymized values\n",
    "  \"\"\"\n",
    "  if type(cols) not in (list, tuple):\n",
    "    cols = [cols]\n",
    "\n",
    "  if not current_map:\n",
    "    current_map = {}\n",
    "\n",
    "  old_keys = set(current_map.keys())\n",
    "  old_vals = set(current_map.values())\n",
    "\n",
    "  new_keys = set()\n",
    "  for col in cols:\n",
    "    new_keys.update(df.loc[~df[col].isnull(), col])\n",
    "    new_keys -= old_keys\n",
    "\n",
    "  # Keep the probability of collisions relatively low, but\n",
    "  # keep the size at least a standard 16 bytes\n",
    "  nbytes = max(4 + int(math.log(len(new_keys) + len(old_keys)) / math.log(8)), 16)\n",
    "  for new_key in new_keys:\n",
    "    new_val = secrets.token_hex(nbytes=nbytes)\n",
    "    while new_val in old_vals:\n",
    "      new_val = secrets.token_hex(nbytes=nbytes)\n",
    "    current_map[new_key] = new_val\n",
    "\n",
    "  if not inplace:\n",
    "    df = df.copy()\n",
    "\n",
    "  for col in cols:\n",
    "    # TODO(khw): Allow an option to map missing data to something else.\n",
    "    df.loc[:, col] = df[col].map(current_map, na_action='ignore')\n",
    "\n",
    "  return df, current_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tanf_anon, map = anonymize_str_columns(df_tanf, \n",
    "                                          cols = ['ic_case_id', 'head_hh', 'address', 'city_state', 'tel', 'pdc_number'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tanf_anon = df_tanf_anon.drop(columns = ['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tanf_anon.to_csv('df_replication_anonymized.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
